# Job Market Insights Dashboard

**Description:**  
This project is a Python application that scrapes job postings across the US from the past years, stores the data in a database, and allows us to analyze and visualize trends in the job market. The goal is to identify key insights about the technologies, skills, and requirements that employers have prioritized over time, and display these insights through an interactive dashboard.

**Project Duration:**  
8 weeks (Start date: 10/7/2024)

---

## Table of Contents
1. [Overview](#overview)
2. [Project Setup](#project-setup)
3. [Installation](#Installation)
4. [Features](#features)
5. [Technologies Used](#technologies-used)
6. [Team](#team)
7. [License](#license)

---

## Overview

**Project Overview:**  
This project focuses on building a job market analysis platform using data scraped from various job boards. By storing this data in a structured format, the platform allows us to derive insights such as the most in-demand job roles, required skills, and technology trends. An interactive dashboard will be created to visualize these insights and make the data accessible for analysis.

**Objectives:**
- Scrape job posting data from online job boards across the US for the past few years.
- Clean and store the data in a database or dataset for analysis.
- Create visualizations to display trends in job postings, such as popular job titles, in-demand skills, and technology usage.
- Provide an interactive dashboard for easy exploration of the data.

---

## Project Setup

### Prerequisites
- Python 3.x
- pip
- Web scraping tools (e.g., BeautifulSoup, Selenium)
- Database (e.g., PostgreSQL, SQLite) or flat file (CSV/JSON) for data storage
- Libraries: pandas, NumPy, matplotlib, seaborn, Dash/Streamlit

### Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/Barderus/job-market-dashboard.git
    cd job-market-dashboard
    ```

2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```


## Features

### Planned Features:
- **Web Scraping:** Automatically scrape job postings from selected job boards.
- **Data Storage:** Store scraped data in a relational database or flat files.
- **Data Analysis:** Extract insights from the dataset (e.g., top technologies, common job titles, salary trends).
- **Interactive Dashboard:** Visualize key insights using interactive graphs and charts.
- **Real-time Scraping:** Automate the scraping process to gather new job postings daily.
- **Advanced Filtering:** Allow users to filter job postings by location, title, and industry.

---

## Technologies Used

- **Programming Languages:** Python
- **Web Scraping Tools:** BeautifulSoup, Selenium
- **Database:** PostgreSQL/SQLite/MongoDB  (for storing job data)
- **Data Analysis:** pandas, NumPy, scikit-learn
- **Visualization:** Matplotlib, Seaborn, Plotly, Dash/Streamlit
- **APIs:** 

---

## Team

**Project Manager:** [Gabriel dos Reis](https://github.com/Barderus)

**Team Members:**  
- {Leo Cortez}
- {Mike Kelley}
- {Zachary Oliver}
- [Quest Hill](https://www.linkedin.com/in/quest-hill/)
- [Cory Camasta](https://github.com/cmasta9)
- [Daniel Cruz](https://www.linkedin.com/in/danielcruzromero/)
---

## License

This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.
